{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ede90d12-6eae-4262-80bf-d9fb62e898dd",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6-8xzGSNGK2y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "6-8xzGSNGK2y",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "811fa811-590d-476d-84e7-1988eb028ce6"
   },
   "outputs": [],
   "source": [
    "# 1) Clone & cd\n",
    "!git clone https://github.com/alonlahav123/DSC291-CLIP-Dissect.git\n",
    "%cd DSC291-CLIP-Dissect\n",
    "\n",
    "# # 2) Install PyTorch & torchvision\n",
    "# !pip install torch torchvision --extra-index-url https://download.pytorch.org/whl/cu117\n",
    "\n",
    "# 3) Install other deps\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "# 3b) install these again (not sure why but this works)\n",
    "!pip install tokenizer ftfy sentence-transformers huggingface-hub\n",
    "\n",
    "# 4) Download the Broden dataset (images only) using\n",
    "!bash dlbroden.sh\n",
    "\n",
    "# 5) (Optional) Download Places-365 ResNet-18\n",
    "# !bash dlzoo_example.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tp_tKTZrMHgl",
   "metadata": {
    "id": "tp_tKTZrMHgl"
   },
   "outputs": [],
   "source": [
    "# 1) upload imagenet_val 2012 after downloading from imagenet website\n",
    "# 2) extract + remove the .tar.gz to save space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd23df1-3e1c-4426-8a6b-c2de740c2950",
   "metadata": {},
   "source": [
    "## Imagenet_val setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5232677-ddbc-47c1-a2c6-fb560a05e891",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd data/imagenet_val\n",
    "\n",
    "# Create the devkit folder if it doesn’t exist\n",
    "mkdir -p ILSVRC2012_devkit_t12/data\n",
    "\n",
    "# Download a known‐good meta.mat\n",
    "wget -O ILSVRC2012_devkit_t12/data/meta.mat \\\n",
    "  https://raw.githubusercontent.com/calebrob6/imagenet_validation/master/data/meta.mat\n",
    "\n",
    "# Download the ground-truth labels (50 000 integers 1–1000)\n",
    "wget -O ILSVRC2012_devkit_t12/data/ILSVRC2012_validation_ground_truth.txt \\\n",
    "  https://raw.githubusercontent.com/calebrob6/imagenet_validation/master/data/ILSVRC2012_validation_ground_truth.txt\n",
    "\n",
    "\n",
    "# Need to organize the 50000 images into 1000 class folders (downloaded dataset is a flat folder with all the images)\n",
    "python3 <<'EOF'\n",
    "import os, numpy as np, scipy.io, shutil\n",
    "\n",
    "# 1) Hardcode the full paths to the new files:\n",
    "meta_mat_path = os.path.expanduser('~/private/DSC291-CLIP-Dissect/data/imagenet_val/ILSVRC2012_devkit_t12/data/meta.mat')\n",
    "gt_path       = os.path.expanduser('~/private/DSC291-CLIP-Dissect/data/imagenet_val/ILSVRC2012_devkit_t12/data/ILSVRC2012_validation_ground_truth.txt')\n",
    "\n",
    "# 2) Where your flat JPEGs live and where to write val_annotations.txt\n",
    "flat_dir  = 'data/imagenet_val/images'\n",
    "anns_file = 'data/imagenet_val/val_annotations.txt'\n",
    "\n",
    "mat = scipy.io.loadmat(meta_mat_path, struct_as_record=False, squeeze_me=True)\n",
    "wnids = [str(s.WNID) for s in mat['synsets']]\n",
    "\n",
    "gt = np.loadtxt(gt_path, dtype=int)\n",
    "\n",
    "imgs = sorted(f for f in os.listdir(flat_dir) if f.lower().endswith('.jpeg'))\n",
    "\n",
    "# 3) Write val_annotations.txt linking each image to its WNID\n",
    "with open(anns_file, 'w') as out:\n",
    "    for img, lbl in zip(imgs, gt):\n",
    "        out.write(f\"{img}\\t{wnids[lbl-1]}\\n\")\n",
    "\n",
    "# 4) Move each JPEG into its synset subfolder\n",
    "for line in open(anns_file):\n",
    "    img, wnid = line.strip().split('\\t')\n",
    "    src = os.path.join(flat_dir, img)\n",
    "    dst = os.path.join(flat_dir, wnid)\n",
    "    os.makedirs(dst, exist_ok=True)\n",
    "    shutil.move(src, os.path.join(dst, img))\n",
    "\n",
    "print(\"✅ Done. Now have\", len(os.listdir(flat_dir)), \"folders under\", flat_dir)\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e254415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see that all the images are classfiied. \n",
    "ls data/imagenet_val/images | wc -l   # should print “1000”"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
